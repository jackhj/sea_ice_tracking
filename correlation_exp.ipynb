{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a cell of text! (Markdown cell)\n",
    "\n",
    "It does nothing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np, math, matplotlib as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True False\n",
      " False False False False False False False  True  True False False False\n",
      " False False False False False  True  True False False False False False\n",
      " False False False  True  True False False False False False False False\n",
      " False  True  True False False False False False False False False  True\n",
      "  True False False False False False False False False  True  True False\n",
      " False False False False False False False  True  True False False False\n",
      " False False False False False  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# in this box we're going to define our grid and data\n",
    "\n",
    "'''this will be size of grid'''\n",
    "gridSize = 100 \n",
    "testGridSize = 9\n",
    "\n",
    "# produce random data values \n",
    "'''eventually this will be brightness temperature data'''\n",
    "data0 = np.random.rand(np.sqrt(gridSize),np.sqrt(gridSize)) * 10\n",
    "# copy the original data and artificially move the array to the right\n",
    "data1 = data0.copy()\n",
    "data1 = np.hstack((data1[:,-1].reshape((data1.shape[0], 1)),data1[:,0:-1]))\n",
    "\n",
    "# define indices\n",
    "I, J = np.meshgrid(np.arange(0,int(np.sqrt(gridSize))),np.arange(0,int(np.sqrt(gridSize))),indexing='ij')\n",
    "I = I.reshape((I.size, 1))\n",
    "J = J.reshape((J.size, 1))\n",
    "\n",
    "# define locations\n",
    "'''eventually this will be lat and lon data'''\n",
    "Y, X = np.meshgrid(10*np.arange(0,int(np.sqrt(gridSize))),10*np.arange(0,int(np.sqrt(gridSize))),indexing='ij')\n",
    "XkeepShape = X\n",
    "YkeepShape = Y\n",
    "X = X.reshape((X.size, 1))\n",
    "Y = Y.reshape((Y.size, 1))\n",
    "\n",
    "N = np.arange(0,X.size)\n",
    "NkeepShape = N.copy()\n",
    "NkeepShape = NkeepShape.reshape((int(np.sqrt(gridSize)), int(np.sqrt(gridSize))))\n",
    "N = N.reshape((N.size, 1))\n",
    "\n",
    "# keep all location data in one array\n",
    "locationData = np.concatenate((N,I,J,Y,X),1)\n",
    "\n",
    "# define a don't bother with mask\n",
    "''' this will contain: landmask (and half landmask to avoid footprint overlap), also mask any point with bad data'''\n",
    "dontBotherMask = np.zeros_like(data0).flatten()\n",
    "\n",
    "# produce an index for transforming data to list of (overlapping) testGrids\n",
    "transformSubI = np.arange(-int(np.floor(np.sqrt(testGridSize)/2)),int(np.floor(np.sqrt(testGridSize)/2))+1,1)\n",
    "transformSubI = np.tile(transformSubI.reshape(transformSubI.size, 1),(1, int(np.sqrt(testGridSize))))\n",
    "transformSubI = transformSubI.reshape((1, transformSubI.size))\n",
    "#print transformSubI\n",
    "\n",
    "# produce an index for transforming data to list of (overlapping) testGrids\n",
    "transformSubJ = np.arange(-int(np.floor(np.sqrt(testGridSize)/2)),int(np.floor(np.sqrt(testGridSize)/2))+1,1)\n",
    "transformSubJ = np.tile(transformSubJ.reshape(1, transformSubJ.size),(int(np.sqrt(testGridSize)), 1))\n",
    "transformSubJ = transformSubJ.reshape((1, transformSubJ.size))\n",
    "#print transformSubJ\n",
    "\n",
    "# broadcast the transformSubs with their big counterparts\n",
    "transformSubI = transformSubI + I\n",
    "transformSubJ = transformSubJ + J\n",
    "\n",
    "#now remove the test grids if they:\n",
    "#    1) contain any negative numbers in I or J\n",
    "#    2) if the dontBotherMask is set\n",
    "removeData = np.logical_or(np.logical_or(transformSubI<0,transformSubJ<0),\n",
    "                           np.logical_or(transformSubI>=data1.shape[0],transformSubJ>=data1.shape[1]))\n",
    "removeData = np.logical_or(np.any(removeData,axis=1),dontBotherMask)\n",
    "\n",
    "transformSubI = transformSubI[removeData==0,:]\n",
    "transformSubJ = transformSubJ[removeData==0,:]\n",
    "locationData = locationData[removeData==0,:]\n",
    "# make an RDD of the index and location data, and also a broadcast variable\n",
    "locationBroadcast = sc.broadcast(locationData)\n",
    "\n",
    "# transform the data:\n",
    "data0 = data0[transformSubI,transformSubJ]\n",
    "data1 = data1[transformSubI,transformSubJ]\n",
    "\n",
    "print removeData\n",
    "print type(removeData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NBroadcast = sc.broadcast(NkeepShape)\n",
    "YBroadcast = sc.broadcast(YkeepShape)\n",
    "XBroadcast = sc.broadcast(XkeepShape)\n",
    "\n",
    "#define a function which returns the Euclidean distance between two points (in the x, y plane)\n",
    "def distance_calc(x1,y1,x2,y2):\n",
    "        \n",
    "    distance = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def distance_calcRDD(line):\n",
    "            \n",
    "    Xs = XBroadcast.value[line[1],line[2]]\n",
    "    Ys = YBroadcast.value[line[1],line[2]]\n",
    "    x1 = Xs[np.floor(float(Xs.size)/2)]\n",
    "    y1 = Ys[np.floor(float(Ys.size)/2)]\n",
    "    \n",
    "    distance = distance_calc(x1,y1,Xs,Ys)\n",
    "    Ns = NBroadcast.value[line[1],line[2]]\n",
    "    \n",
    "    keepData = np.logical_and(np.logical_and(distance<=distThresholdBC.value,distance!=0),\n",
    "                          np.any(Ns==locationBroadcast.value[:,0:1],axis=0))\n",
    "    \n",
    "    Ns = Ns[keepData==1]\n",
    "    \n",
    "    return (line[0], list(Ns))\n",
    "    \n",
    "    \n",
    "# Doing a cartesian product of every grid cell against every other grid cell is really, really inefficient.\n",
    "# So, first we will filter the combinations of matches by their distance between each other on the grid.\n",
    "# distGridThreshold is the maximum number of grid spaces which can be moved\n",
    "'''eventually this will be: max(possible distance to move)/min(possible distances between grid points)'''\n",
    "distGridThreshold = 4\n",
    "\n",
    "# this is the physical distance that will be the threshold for the movement of ice\n",
    "'''eventually will be the distance possible to move (in km) over 1 day at 1m/s (24 * 60 * 60 * 1 / 1000)'''\n",
    "distThresholdBC = sc.broadcast(30)\n",
    "\n",
    "# produce an index for checking distances\n",
    "distCheckSubI = np.arange(-distGridThreshold,distGridThreshold+1,1)\n",
    "distCheckSubI = np.tile(distCheckSubI.reshape(distCheckSubI.size, 1),(1, 2*distGridThreshold+1))\n",
    "distCheckSubI = distCheckSubI.reshape((1, distCheckSubI.size))\n",
    "distCheckSubI = distCheckSubI + I\n",
    "distCheckSubI = distCheckSubI[removeData==0,:]\n",
    "\n",
    "# produce an index for checking distances\n",
    "distCheckSubJ = np.arange(-distGridThreshold,distGridThreshold+1,1)\n",
    "distCheckSubJ = np.tile(distCheckSubJ.reshape(1, distCheckSubJ.size),(2*distGridThreshold+1, 1))\n",
    "distCheckSubJ = distCheckSubJ.reshape((1, distCheckSubJ.size))\n",
    "distCheckSubJ = distCheckSubJ + J\n",
    "distCheckSubJ = distCheckSubJ[removeData==0,:]\n",
    "\n",
    "# replace any data which is out of bounds with [0, 0]\n",
    "badData = np.logical_or(np.logical_or(distCheckSubI<0,distCheckSubI>=XkeepShape.shape[0]),\n",
    "           np.logical_or(distCheckSubJ<0,distCheckSubJ>=XkeepShape.shape[1]))\n",
    "\n",
    "distCheckSubI[badData==1] = 0\n",
    "distCheckSubJ[badData==1] = 0\n",
    "\n",
    "# chuck the location number (which is ABSOLUTE, rather than tied to locationData size) and the indices\n",
    "# into an RDD and map to a len=3 tuple\n",
    "distCheckSub = np.concatenate((locationData[:,0:1],distCheckSubI,distCheckSubJ),1)\n",
    "distCheckSubRDD = (sc.parallelize(distCheckSub,4)\n",
    "                   .map(lambda a: (a[0],a[1:(2*distGridThreshold+1)**2+1], a[(2*distGridThreshold+1)**2+1:])))\n",
    "\n",
    "distanceDictRDD = (distCheckSubRDD\n",
    "                   .map(distance_calcRDD)\n",
    "                   .cache())\n",
    "\n",
    "#print distanceDictRDD.filter(lambda (a, b): a==31).collect()\n",
    "#print distanceDictRDD.collect()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16, [14, 15, 17, 18, 24, 25, 26, 27, 28, 34, 35, 36, 37, 38])]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#reformat the distanceDictRDD to the correct dictionary-like object\n",
    "def makeDistFunc(line):\n",
    "    \n",
    "    key = line[0]\n",
    "    tempList = line[1]\n",
    "    \n",
    "    return (key, list(line[1]))\n",
    "\n",
    "\n",
    "#locationDataRDD = sc.parallelize(locationData, 4)\n",
    "\n",
    "# take the cartesian product and compute the distance between each point: filter by distance threshold\n",
    "# distanceDataRDD contains the info about each point, and the other points which are less than the distance\n",
    "# threshold away\n",
    "#'''this process needs to be sped up'''\n",
    "#distanceDataRDD = (locationDataRDD\n",
    "#                   .cartesian(locationDataRDD)\n",
    "#                   .map(lambda (a, b): (a, (b, distance_calc(a[3],a[4],b[3],b[4]))))\n",
    "#                   .filter(lambda (a, (b, dist)): dist < distThreshold and dist != 0)\n",
    "#                   .map(lambda (a, (b, dist)): (a[0], b[0])))\n",
    "\n",
    "# now reduce by key to list those points within range\n",
    "distanceDictRDD = (distanceDataRDD\n",
    "                   .groupByKey()\n",
    "                   .map(makeDistFunc)\n",
    "                   .sortByKey()\n",
    "                   .cache())\n",
    "\n",
    "print distanceDictRDD.filter(lambda (a, b): a==16).collect()\n",
    "#print np.arange(0,100).reshape((10,10))\n",
    "#print distanceDictRDD.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([3, 1]), array([ 0, 10]))\n"
     ]
    }
   ],
   "source": [
    "# define a function which collects the broadcast data into an RDD\n",
    "# can also put correlation in here if you like\n",
    "def computeCorrelation(line):\n",
    "        \n",
    "    # extract relevant data from the daily broadcast variables\n",
    "    getdata0 = data0Broadcast.value[line[0]==locationBroadcast.value[:,0],:]\n",
    "    \n",
    "    grabBinary = np.any(locationBroadcast.value[:,0].reshape((locationBroadcast.value[:,0].size, 1))==line[1],axis=1)\n",
    "    getdata1 = data1Broadcast.value[grabBinary,:]\n",
    "            \n",
    "    # tile data0 for fast correlation\n",
    "    getdata0 = np.tile(getdata0-np.mean(getdata0),(getdata1.shape[0], 1))\n",
    "    getdata1 = getdata1 - np.mean(getdata1,axis=1).reshape((getdata1.shape[0], 1))\n",
    "    \n",
    "    correl = np.sum(getdata0*getdata1,axis=1) / (np.sqrt(np.sum(getdata0*getdata0,axis=1)) * np.sqrt(np.sum(getdata1*getdata1,axis=1)))\n",
    "    \n",
    "    return (line[0], line[1], correl)\n",
    "\n",
    "# find the largest correlation\n",
    "'''this also needs work on: threshold value, and sharpness of peak.\n",
    "Can find threshold value by computing distribution of correlations amongst motions which could never occur.\n",
    "Then take 90th percentile: should remove all but 10% of bad matches.'''\n",
    "def findLargestCorrel(line):\n",
    "    \n",
    "    correl = line[2]\n",
    "    maximum = line[1][correl.argmax()]\n",
    "    \n",
    "    xvel = locationBroadcast.value[maximum==locationBroadcast.value[:,0],4] - locationBroadcast.value[line[0]==locationBroadcast.value[:,0],4]\n",
    "    yvel = locationBroadcast.value[maximum==locationBroadcast.value[:,0],3] - locationBroadcast.value[line[0]==locationBroadcast.value[:,0],3]\n",
    "        \n",
    "    i = locationBroadcast.value[line[0]==locationBroadcast.value[:,0],1]\n",
    "    j = locationBroadcast.value[line[0]==locationBroadcast.value[:,0],2]\n",
    "    \n",
    "    return (np.hstack((i, j)), np.hstack((yvel,xvel)))\n",
    "\n",
    "print findLargestCorrel(computeCorrelation((31, [11, 12, 13, 21, 22, 23, 32, 33, 41, 42, 43, 51, 52, 53])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# turn data0 and data1 into broadcast variables\n",
    "data0Broadcast = sc.broadcast(data0)\n",
    "data1Broadcast = sc.broadcast(data1)\n",
    "\n",
    "correlationRDD = (distanceDictRDD\n",
    "            .map(computeCorrelation)\n",
    "            .map(findLargestCorrel)\n",
    "            .cache())\n",
    "            \n",
    "#print correlationRDD.collect()\n",
    "#print np.arange(0,100).reshape((10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0.  20.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0.  10.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0. -20.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0. -20.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0. -20.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0. -30.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0. -30.  nan]\n",
      " [ nan   0.   0.   0.   0.   0.   0.   0. -10.  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]]\n",
      "[[ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10. -20.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10. -10.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10. -10.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10. -10.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10. -10.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10.   0.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10.   0.  nan]\n",
      " [ nan  10.  10.  10.  10.  10.  10.  10. -20.  nan]\n",
      " [ nan  nan  nan  nan  nan  nan  nan  nan  nan  nan]]\n"
     ]
    }
   ],
   "source": [
    "# now need to reconstruct original data format\n",
    "# to do this, we are going to collect 2 RDDS\n",
    "\n",
    "# one for the location of output\n",
    "outputLocation = np.array(correlationRDD\n",
    "                 .flatMap(lambda (a, b): a)\n",
    "                 .collect())\n",
    "outputLocation = outputLocation.reshape((outputLocation.size/2, 2))\n",
    "\n",
    "# one for the distance travelled\n",
    "outputDist = np.array(correlationRDD\n",
    "                 .flatMap(lambda (a, b): b)\n",
    "                 .collect())\n",
    "outputDist = outputDist.reshape((outputDist.size/2, 2))\n",
    "\n",
    "\n",
    "yDist = np.ones((np.sqrt(gridSize),np.sqrt(gridSize)))*np.nan\n",
    "xDist = np.ones((np.sqrt(gridSize),np.sqrt(gridSize)))*np.nan\n",
    "\n",
    "'''These need to be divided by the time period'''\n",
    "yDist[outputLocation[:,0],outputLocation[:,1]] = outputDist[:,0]\n",
    "xDist[outputLocation[:,0],outputLocation[:,1]] = outputDist[:,1]\n",
    "\n",
    "#print outputLocation\n",
    "#print outputLocation[1:2:]\n",
    "print yDist\n",
    "print xDist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
